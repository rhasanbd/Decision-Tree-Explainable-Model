# Decision Tree - An Explainable Model

If github in unable to render a Jupyter notebook, copy the link of the notebook and enter into the nbviewer: https://nbviewer.jupyter.org/


These notebooks provide an introduction to the Decision Tree model. 

- Notebook 1: Decision Tree: Training & Visualization

In this notebook, we introduce the Decision Tree model and the CART (Classification and Regression Trees) algorithm for its training.

      -- Motivate the Decision Tree model by comparing it with the ANN

      -- Common sense reasoning using Decision Tree

      -- Decision Tree: Advantages & Disadvantages

      -- Decision Tree: Algorithms

      -- Decision Tree: Computational Complexity

      -- Training Decision Tree using the CART algorithm

      -- Visualize a Decision Tree using Graphviz Graph Visualization software

      -- Study the Main Limitation of Decision Tree: High Variance


- Notebook 2: Decision Tree: Model Selection & Combating Overfitting

      -- Task 1: Model selection for a Decision Tree Classifier via hyperparameter tuning

      -- Task 2: Understand how hyperparameter tuning reduces variance (handles overfitting)
      
      
- Notebook 3: Decision Tree: Regression

In this notebook, we perform regression using the Decision Tree model and compare its performance with other regression models.

      -- Decision Tree Regression

      -- Random Forest Regression

      -- Linear Regression by using the Ordinary Least Squared (OLS) technique

      -- Polynomial Regression (Regularized)


- Notebook 4: Decision Tree: Feature Selection

In this notebook, we perform feature selection using the Decision Tree model. It enables us to detrmine the relative importance of each feature, then select the features of higher importance.

The Decision Tree training algorithm, e.g., classification and regression trees (CART), provides importance scores of the features. It measures a featureâ€™s importance by looking at how much the tree nodes that use that feature reduce impurity based on the Gini index or entropy.
